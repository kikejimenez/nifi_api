{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "permanent-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bright-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import json\n",
    "from os import environ\n",
    "from time import sleep\n",
    "from nifi_api.dataflow import DataFlow\n",
    "from nifi_api.environment import DataFlowIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "specified-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp source_to_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-spider",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Source To Refined\n",
    "> Monitors three dataflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sticky-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NifiIds:\n",
    "    \"\"\" The collection of the DataFlowIds:\n",
    "          - source to raw\n",
    "          - raw to discovery\n",
    "          - discovery to refined\n",
    "    \"\"\"\n",
    "\n",
    "    nifi_json_ids = json.load(open(environ['CONFIG_FILE']))['NifiIds']\n",
    "\n",
    "    sourceToRaw = DataFlowIds(pipeline=nifi_json_ids['SourceToRaw'])\n",
    "    rawToDiscovery = DataFlowIds(pipeline=nifi_json_ids['RawToDiscovery'])\n",
    "    discoveryToRefined = DataFlowIds(\n",
    "        pipeline=nifi_json_ids['DiscoveryToRefined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abstract-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline watching has started..\n",
      "Pipeline watching has finished ...\n"
     ]
    }
   ],
   "source": [
    "source_to_raw = DataFlow(NifiIds.sourceToRaw,delay_seconds_between_checks=30)\n",
    "source_to_raw.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "buried-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def source_to_refined():\n",
    "    \"\"\" The Source To Refined dataflow is decomposed in three sequential steps:\n",
    "        - Source To Raw\n",
    "        - Raw To Discovery\n",
    "        - Discovery To Refined\n",
    "    This function assures that each of these steps starts only after the\n",
    "    previous step has finished.\n",
    "    \"\"\"\n",
    "\n",
    "    # time between steps\n",
    "    T = 15\n",
    "    time_after_start = 15\n",
    "\n",
    "    time_between_checks = 15\n",
    "\n",
    "    source_to_raw = DataFlow(\n",
    "        NifiIds.sourceToRaw,\n",
    "        delay_seconds_after_start=time_after_start,\n",
    "        delay_seconds_between_checks=time_between_checks,\n",
    "    )\n",
    "    raw_to_discovery = DataFlow(\n",
    "        NifiIds.rawToDiscovery,\n",
    "        delay_seconds_after_start=time_after_start,\n",
    "        delay_seconds_between_checks=time_between_checks,\n",
    "    )\n",
    "    discovery_to_refined = DataFlow(\n",
    "        NifiIds.discoveryToRefined,\n",
    "        delay_seconds_after_start=time_after_start,\n",
    "        delay_seconds_between_checks=time_between_checks,\n",
    "    )\n",
    "\n",
    "    source_to_raw.run()\n",
    "    sleep(T)\n",
    "    raw_to_discovery.run()\n",
    "    sleep(T)\n",
    "    discovery_to_refined.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greater-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def source_to_discovery():\n",
    "    \"\"\" The Source To Refined dataflow is decomposed in three sequential steps:\n",
    "        - Source To Raw\n",
    "        - Raw To Discovery\n",
    "    This function assures that each of these steps starts only after the\n",
    "    previous step has finished.\n",
    "    \"\"\"\n",
    "\n",
    "    # time between steps\n",
    "    T = 15\n",
    "    time_after_start = 15\n",
    "\n",
    "    time_between_checks = 15\n",
    "\n",
    "    source_to_raw = DataFlow(\n",
    "        NifiIds.sourceToRaw,\n",
    "        delay_seconds_after_start=time_after_start,\n",
    "        delay_seconds_between_checks=time_between_checks,\n",
    "    )\n",
    "    raw_to_discovery = DataFlow(\n",
    "        NifiIds.rawToDiscovery,\n",
    "        delay_seconds_after_start=time_after_start,\n",
    "        delay_seconds_between_checks=time_between_checks,\n",
    "    )\n",
    "    source_to_raw.run()\n",
    "    sleep(T)\n",
    "    raw_to_discovery.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optional-canon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline watching has started..\n",
      "Pipeline watching has finished ...\n",
      "pipeline watching has started..\n",
      "Pipeline watching has finished ...\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "# Benchmark Test\n",
    "# 1. Update a valid 1 GB file in to the S3 bucket, i.e., campaigns.csv\n",
    "# 2. Run *source_to_refined* and track its execution time\n",
    "source_to_discovery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cloudy-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_environment.ipynb.\n",
      "Converted 02_rest.ipynb.\n",
      "Converted 03_dataflow.ipynb.\n",
      "Converted 04_source_to_refined.ipynb.\n",
      "Converted 09_tools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-organizer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
