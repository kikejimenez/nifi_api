{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import time\n",
    "\n",
    "from nifi_api.rest import Flowfiles, Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-review",
   "metadata": {},
   "source": [
    "# Dataflow\n",
    "\n",
    ">   Monitors and controls a Nifi Dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class DataFlow:\n",
    "    \"\"\"\n",
    "    Monitors and controls a Nifi dataflow. The dataflow starts\n",
    "    when the **run** method is called.\n",
    "\n",
    "    Parameters\n",
    "   -------------\n",
    "\n",
    "      dataFlowIds: DataFlowIds\n",
    "        data structure that contains all the IDs of the in/out\n",
    "        processors and connections\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataflow_ids: object,\n",
    "        delay_seconds_after_start: int = 14,\n",
    "        delay_seconds_between_checks: int = 15,\n",
    "    ) -> None:\n",
    "        self.in_processor = Processor(dataflow_ids.in_processor)\n",
    "        self.in_flowfiles = Flowfiles(dataflow_ids.in_connection)\n",
    "        self.middle_processor = Processor(dataflow_ids.middle_processor)\n",
    "        self.out_processor = Processor(dataflow_ids.out_processor)\n",
    "        self.out_flowfiles = Flowfiles(dataflow_ids.out_connection)\n",
    "\n",
    "        self.seconds_after_start = delay_seconds_after_start\n",
    "        self.seconds_between_checks = delay_seconds_between_checks\n",
    "\n",
    "    def run(self) -> None:\n",
    "\n",
    "        print('pipeline watching has started..')\n",
    "\n",
    "        self.out_processor.update_run_status(\"STOPPED\")\n",
    "        self.in_processor.update_run_status(\"RUNNING\")\n",
    "        time.sleep(self.seconds_after_start)\n",
    "        self.in_flowfiles.get_ids()\n",
    "        self.middle_processor.update_run_status(\"RUNNING\")\n",
    "        self.in_processor.update_run_status(\"STOPPED\")\n",
    "\n",
    "        while True:\n",
    "\n",
    "            self.out_flowfiles.get_ids()\n",
    "\n",
    "            if self.in_flowfiles.equals(self.out_flowfiles):\n",
    "\n",
    "                self.middle_processor.update_run_status(\"STOPPED\")\n",
    "                self.out_processor.update_run_status(\"RUNNING\")\n",
    "                print(\"Pipeline watching has finished ...\")\n",
    "                break\n",
    "            time.sleep(self.seconds_between_checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline watching has finished ...\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# Uses the group processor *Test API* in the Cloudera session.\n",
    "\n",
    "# 1. Turn on the  \"Initial\" and \"Middle\" processors, turn off the\n",
    "#    \"Body\" and \"Final\" processors.\n",
    "\n",
    "# 2. Generate the data structure with the connections and processors Ids\n",
    "\n",
    "from nifi_api.environment import DataFlowIds\n",
    "ids = {\n",
    "    \"in_connection\": {\n",
    "        \"Id\": \"cc549c6e-0177-1000-ffff-ffffb5d2aba2\",\n",
    "        \"name\": \"First\"\n",
    "    },\n",
    "    \"out_connection\": {\n",
    "        \"Id\": \"51ab3b24-084f-1309-0000-00001946f2c7\",\n",
    "        \"name\": \"Final\"\n",
    "    },\n",
    "    \"in_processor\": {\n",
    "        \"Id\": \"36c62ad6-d606-3b04-9743-d77b6249608c\",\n",
    "        \"name\": \"First\"\n",
    "    },\n",
    "    \"middle_processor\": {\n",
    "        \"Id\": \"cc54862f-0177-1000-ffff-ffffe7325a20\",\n",
    "        \"name\": \"Middle\"\n",
    "    },\n",
    "    \"out_processor\": {\n",
    "        \"Id\": \"51ab3b1e-084f-1309-a135-aa0100d7186b\",\n",
    "        \"name\": \"Final\"\n",
    "    },\n",
    "}\n",
    "data_ids = DataFlowIds(ids)\n",
    "\n",
    "# 4. Instantiate the DataFlow class as follows:\n",
    "test_dataflow = DataFlow(\n",
    "    dataflow_ids=data_ids,\n",
    "    delay_seconds_after_start=10,\n",
    "    delay_seconds_between_checks=10,\n",
    ")\n",
    "# Call the run method. The following events must happen:\n",
    "#  - \"First\" and \"Last\" proccessor turn on and off, respectively.\n",
    "#  - \"First\" processor turns off and \"Middle\" processor turns on\n",
    "#  - \"Final\" turns on\n",
    "\n",
    "test_dataflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_environment.ipynb.\n",
      "Converted 02_rest.ipynb.\n",
      "Converted 03_dataflow.ipynb.\n",
      "Converted 04_source_to_refined.ipynb.\n",
      "Converted 09_tools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-words",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
